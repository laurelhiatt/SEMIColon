configfile: '/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/config/snakemake_config/LeeSixconfig.yaml'
in_dir: str = config["input_directory"]
out_dir: str = config["output_directory"]
reference: str = config["reference_genome"]
reference_index: str = config["reference_genome_index"]
samples: list[str] = config["samples"]
donors: list[str] = config["donors"]
nchunks = config["nchunks"]
chunks = list(range(1,nchunks+1))
chroms = ["1","2","3","4","6","7","8","9","10","11","12","13","14","15","16","17",
"18","19","20","21","22","X","Y"]

# matches = {
#     'HLS': {'crypt_samples': ['HLS_1C_30_B5', 'HLS_1C_30_D5', 'HLS_1C_30_G5', 'HLS_1C_30_H5', 'HLS_2C_30_D6', 'HLS_2C_30_E6']},
#     'PD28690': {'crypt_samples': ['PD28690bx_2_a5', 'PD28690bx_2_d5', 'PD28690cb_2_g3', 'PD28690cb_2_h3']},
#     'PD34199': {'crypt_samples': ['PD34199a_c17', 'PD34199a_c22', 'PD34199a_c27', 'PD34199a_c28', 'PD34199a_c31', 'PD34199a_c3', 'PD34199a_c5', 'PD34199a_c7', 'PD34199a_t31', 'PD34199a_t28']},
#     'PD34202': {'crypt_samples': ['PD34202a_s9']}
#     }

matches = {
    'HLS': {'crypt_samples': ['HLS_1C_30_B5']},
    'PD34199': {'crypt_samples': ['PD34199a_t28']},
    }

### IMPORTS ###
import os
import re

# Wildcard constraints; should all be alphanumeric
wildcard_constraints:
    sample = "[A-Za-z0-9_]+",
    chroms = "[A-Za-z0-9]+",
    i = "[0-9]+",
    out_dir = out_dir,
    donor = "[A-Za-z0-9]+"


rule all:
    input:
        expand("{out_dir}/bam/{sample}-sorted.bam.bai", out_dir = out_dir, sample = samples, donor = donors),
        expand("{out_dir}/bam/{sample}-sorted.stats", out_dir = out_dir, sample = samples, donor = donors),
        expand("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf", out_dir = out_dir, sample = samples, donor = donors, chroms = chroms, i = chunks),

        #expand("{out_dir}/vcf/{donor}-var.vcf", out_dir = out_dir, donor = matches.keys()),

def get_donor(sample, matches):
    for donor, samples in matches.items():
        if sample in samples['crypt_samples']:
            return donor
    raise KeyError(f"Sample {sample} not found in matches dictionary")

# from downloaded crams
rule align_and_sort:
    input:
        cram = lambda wc: f"{in_dir}/{get_donor(wc.sample, matches)}/{wc.sample}_final.cram"

    output:
        bam_sort = temp("{out_dir}/bam/{sample}-sortednoRG.bam")

    shell:
        """
        echo "Input CRAM file: {input.cram}"
        echo "Output BAM file: {output.bam_sort}"
        samtools sort -o {output.bam_sort} {input.cram}
        echo "Successfully sorted CRAM to BAM: {output.bam_sort}"
        """


rule addrg:
    input:
        bam_sort = rules.align_and_sort.output.bam_sort
    output:
        sort_bam_RG = "{out_dir}/bam/{sample}-sorted.bam"
    params:
        donor = lambda wildcards: get_donor(wildcards.sample, matches)
    shell:
        """
        samtools addreplacerg -r "@RG\\tID:{params.donor}_{wildcards.sample}\\tSM:{params.donor}\\tLB:{params.donor}_{wildcards.sample}\\tPL:Illumina" {input.bam_sort} | \
        samtools view -b > {output.sort_bam_RG}
        """

rule index_bam:
    input:
        bam_sort = rules.addrg.output.sort_bam_RG
    output:
        bai = "{out_dir}/bam/{sample}-sorted.bam.bai"
    shell:
        """
        samtools index {input.bam_sort}
        """

rule check_bam:
    input:
        bam_sort = rules.addrg.output.sort_bam_RG
    output:
        stats = "{out_dir}/bam/{sample}-sorted.stats"
    shell:
        """
        samtools stats {input.bam_sort} > {output.stats}
        """

rule generateregions:
    input:
        reference = reference,
        out_dir = out_dir
    params:
        chunks = chunks
    output:
        regions = expand("{out_dir}/regions/chunk.{chroms}.region.{i}.bed", i = chunks, out_dir = out_dir, chroms = chroms)
    shell:
        # "../scripts/GenerateFreebayesRegions.R" # This is located in the scripts/ directory of freebayes
        "python /uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/scripts/variant_calling/fasta_generate_regions.py --fai {input.reference} --chunks 9 --bed {input.out_dir}/regions/chunk"

# # Current filtering:
# ### min-alternate-count 2
rule freebayes_variant_calling:
    input:
        bam_sort = lambda wildcard: expand("{out_dir}/bam/{sample}-sorted.bam", sample=samples, out_dir=out_dir),
        bai = lambda wildcard: expand("{out_dir}/bam/{sample}-sorted.bam.bai", sample=samples, out_dir=out_dir),
        ref = reference,
        regions = "{out_dir}/regions/chunk.{chroms}.region.{i}.bed"
    output:
        full = "{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf",
    params:
        location = "{out_dir}/bam/"
    resources:
        mem_mb = 16000
    run:
        donor = wildcards.donor
        crypt_samples = matches[donor]["crypt_samples"]

        # Create a temporary file for BAM file paths
        bam_file_list = temp(f"bam_list_{wildcards.donor}_{wildcards.i}.txt")

        with open(bam_file_list, "w") as f:
            for sample in crypt_samples:
                f.write(f"{params.location}{sample}-sorted.bam\n")

        shell("""
            RAW_VCF={output.full}

            freebayes --min-alternate-count 2 --debug -f {input.ref} -t {input.regions} -L {bam_file_list} > $RAW_VCF
        """)


            #        full_index = temp("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz.tbi")

#            RAW_VCF=${{RAW_VCF%%.gz}}
           # bgzip -f $RAW_VCF
           # tabix -f -p vcf {output.full}

# rule ConcatVCFs:
#     input:
#         chunk_vcf = lambda wildcard: expand("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz", i=chunks, out_dir=wildcard.out_dir, donor=wildcard.donor, chroms=chroms),
#         chunk_vcf_index = lambda wildcard: expand("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz.tbi", i=chunks, out_dir=wildcard.out_dir, donor=wildcard.donor, chroms=chroms)
#     output:
#         vcf = "{out_dir}/vcf/{donor}-var.vcf.gz"
#     shell:
#         """
#         RAW_VCF={output.vcf}
#         bcftools concat -a {input.chunk_vcf} > $RAW_VCF
#         bgzip -f $RAW_VCF
#         tabix -f -p vcf {output.vcf}
#         """