# /scratch/ucgd/lustre-work/quinlan/data-shared/datasets/spermseq/wgs

#configfile: "/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/config.yaml"

### IMPORTS ###
import snakemake
import os
import re

# Pipeline plans
# - Align fastqs to reference genome
#     - I do *not* need to merge the R1s and R3s
#     - We think I do not need to trim (for now)
#     - Lets do whatever Lee-Six did, to hg38
# - Variant calling (Call mutations)
#     - FreeBayes?
#     - DeepVariant?
#     - Likely SNVs, maybe indels?
# - Pipeline to process called variants/Vcf
#     - PASS variants, filter
# - Mutational signatures
#     - https://github.com/HLee-Six/colon_microbiopsies what Lee-Six did (in R)
# - Mutational spectra
# - Make plots and save to rational places


samples: list[str] = [
    "test"
]

# Wildcard constraints; should all be alphanumeric
wildcard_constraints:
    sample = "[A-Za-z0-9]+"

# Rule 'all', defining all requested output.
rule all:
    input:
        expand("../data/{sample}-sorted.bai", sample = samples)

# Rule 'fastp' preprocesses the reads by detecting and removing adapters,
# filtering reads with an average quality less than 20, and producing
# filtered fastq reads with preprocessing reports.
rule fastp:
    input:
        R1="../data/{sample}_R1.fastq.gz",
        R3="../data/{sample}_R3.fastq.gz"
    output:
        r1_clean = "../data/{sample}_R1.clean.fastq",
        r3_clean = "../data/{sample}_R3.clean.fastq",
        html_report = "../reports/{sample}-fastp-report.html",
        json_report = "../reports/{sample}-fastp-report.json"
    shell:
        """
        fastp --in1 {input.R1} --in2 {input.R3} \
        --out1 {output.r1_clean} --out2 {output.r3_clean} \
        --detect_adapter_for_pe \
        --average_qual 20 \
        --thread {threads} \
        --html {output.html_report} \
        --json {output.json_report}
        """

# Aligns cleaned fastq reads to the defined reference genome
# Mark duplicates and extract discordant and split reads from sam files
# Convert to bam
rule bwa_mem_bam:
    input:
        r1_clean = "../data/{sample}_R1.clean.fastq",
        r3_clean = "../data/{sample}_R3.clean.fastq",
        fasta="/scratch/ucgd/lustre/common/data/Reference/GRCh38/human_g1k_v38_decoy_phix.fasta"
    output:
       zip_bam = "../data/{sample}.bam.gz"
    threads: 8
    conda: "../data/semicolonsmk.yaml"
    shell:
        "bwa mem -t {threads} {input.fasta} {input.r1_clean} {input.r3_clean} | samblaster | samtools view -b > {output.zip_bam}"

rule gunzip:
    input:
        zip_bam = "../data/{sample}.bam.gz"
    output:
        bam = "../data/{sample}.bam"
    shell:
        """
        gunzip {input.zip_bam} > {output.bam}
        """

rule sort_bam:
    input:
        bam = "../data/{sample}.bam"
    output:
        bam_sort = "../data/{sample}-sorted.bam"
    shell:
        """
        samtools sort {input.bam} -o {output.bam_sort}
        """

rule index_bam:
    input:
        bam_sort = "../data/{sample}-sorted.bam"
    output:
        bai = "../data/{sample}-sorted.bai"
    shell:
        """
        samtools index -b {input.bam_sort} -o {output.bai}
        """