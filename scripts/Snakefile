configfile: '../data/config.yaml'
in_dir: str = config["input_directory"]
out_dir: str = config["output_directory"]
reference: str = config["reference_genome"]
reference_index: str = config["reference_genome_index"]
samples: list[str] = config["samples"]
nchunks = config["nchunks"]
chunks = list(range(1,nchunks+1))
chroms = ["chr1","chr2","chr3","chr4","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17",
"chr18","chr19","chr20","chr21","chr22","chrX","chrY"]

matches = {
    'D212_92N8014': {'sperm_samples': ['19841X5', '19841X10'], 'blood_sample': '19841X15'},
    'D100_VG6U010': {'sperm_samples': ['19841X4', '19841X9'], 'blood_sample': '19841X14'},
    'D091_IX8Y012': {'sperm_samples': ['19841X3', '19841X8'], 'blood_sample': '19841X13'},
    'D127_V5ET001': {'sperm_samples': ['19841X2', '19841X7'], 'blood_sample': '19841X12'},
    'D130_WN11-001': {'sperm_samples': ['19841X1', '19841X6'], 'blood_sample': '19841X11'}
}

### IMPORTS ###
import os
import re

# Wildcard constraints; should all be alphanumeric
wildcard_constraints:
    sample = "[A-Za-z0-9]+",
    chroms = "[A-Za-z0-9]+",
    i = "[0-9]+",
    out_dir = out_dir

# Rule 'all', defining all requested output.
rule all:
    input:
        expand("{out_dir}/bam/{sample}-sorted.bai", out_dir = out_dir, sample = samples),
        expand("{out_dir}/vcf/{donor}-var.vcf.gz", out_dir = out_dir, donor = matches.keys())

# Rule 'fastp' preprocesses the reads by detecting and removing adapters,
# filtering reads with an average quality less than 20, and producing
# filtered fastq reads with preprocessing reports.
rule fastp:
    input:
        R1 = in_dir + "/{sample}_R1.merged.trimmed.fastq.gz",
        R2 = in_dir + "/{sample}_R2.merged.trimmed.fastq.gz"
    output:
        r1_clean = "{out_dir}/fastq/{sample}_R1.clean.fastq",
        r2_clean = "{out_dir}/fastq/{sample}_R2.clean.fastq",
        html_report = "{out_dir}/reports/{sample}-fastp-report.html",
        json_report = "{out_dir}/reports/{sample}-fastp-report.json"
    shell:
        """
        fastp --in1 {input.R1} --in2 {input.R2} \
        --out1 {output.r1_clean} --out2 {output.r2_clean} \
        --detect_adapter_for_pe \
        --average_qual 20 \
        --thread 10 \
        --html {output.html_report} \
        --json {output.json_report}
        """

# Aligns cleaned fastq reads to the defined reference genome
# Mark duplicates and extract discordant and split reads from sam files
# Convert to bam (exclude unmapped reads with -F 4)
rule align_and_sort:
    input:
        r1_clean = rules.fastp.output.r1_clean,
        r2_clean = rules.fastp.output.r2_clean,
        ref = reference
    output:
        bam_sort = temp("{out_dir}/bam/{sample}-sortednoRG.bam")
    threads: 8
    shell:
        """
        bwa mem -t {threads} {input.ref} {input.r1_clean} {input.r2_clean} | samblaster | samtools view -b | samtools sort -o {output.bam_sort}
        """

def get_donor(sample, matches):
    for donor, samples in matches.items():
        if sample in samples['sperm_samples'] or sample == samples['blood_sample']:
            return donor
    raise KeyError(f"Sample {sample} not found in matches dictionary")

rule addrg:
    input:
        bam_sort = rules.align_and_sort.output.bam_sort
    output:
        sort_bam_RG = "{out_dir}/bam/{sample}-sorted.bam"
    params:
        donor = lambda wildcards: get_donor(wildcards.sample, matches)
    shell:
        """
        samtools addreplacerg -r "@RG\\tID:{params.donor}_{wildcards.sample}\\tSM:{params.donor}_{wildcards.sample}\\tLB:{params.donor}_{wildcards.sample}\\tPL:Illumina" {input.bam_sort} | \
        samtools view -b > {output.sort_bam_RG}
        """

rule index_bam:
    input:
        bam_sort = rules.addrg.output.sort_bam_RG
    output:
        bai = "{out_dir}/bam/{sample}-sorted.bai"
    shell:
        """
        samtools index -b {input.bam_sort} -o {output.bai}
        """

rule generateregions:
    input:
        index = reference_index,
    params:
        chunks = chunks
    output:
        regions = expand("{out_dir}/regions/chunk.{chroms}.region.{i}.bed", i = chunks, out_dir = out_dir, chroms = chroms)
    shell:
        # "../scripts/GenerateFreebayesRegions.R" # This is located in the scripts/ directory of freebayes
        "python variant_calling/fasta_generate_regions.py {input.index} --chunks 9 --bed ../data/output/regions/chunk"

# Current filtering:
### min-alternate-count 2
rule freebayes_variant_calling:
    input:
        bam_sort = lambda wildcard: expand("../data/output/bam/{sample}-sorted.bam", sample = samples),
        bai = lambda wildcard: expand("../data/output/bam/{sample}-sorted.bai", sample = samples),
        ref = reference,
        regions = "../data/output/regions/chunk.{chroms}.region.{i}.bed"
    output:
        full = temp("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz"),
        full_index = temp("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz.tbi")
    params:
        location = "../data/output/bam/"
    run:
        donor = wildcards.donor
        blood = matches[donor]["blood_sample"]
        sperm1 = matches[donor]["sperm_samples"][0]
        sperm2 = matches[donor]["sperm_samples"][1]

        shell("""
            RAW_VCF={output.full}
            RAW_VCF=${{RAW_VCF%%.gz}}

            freebayes --min-alternate-count 2 -f {input.ref} -t {input.regions} {params.location}{blood}-sorted.bam {params.location}{sperm1}-sorted.bam {params.location}{sperm2}-sorted.bam > $RAW_VCF

            bgzip -f $RAW_VCF
            tabix -f -p vcf {output.full}
        """)

rule ConcatVCFs:
    input:
        chunk_vcf = lambda wildcard: expand("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz", i = chunks, out_dir = wildcard.out_dir, donor = wildcard.donor, chroms = chroms),
        chunk_vcf_index = lambda wildcard: expand("{out_dir}/vcf/{chroms}/{donor}-variants.{i}.vcf.gz.tbi", i = chunks, out_dir = wildcard.out_dir, donor = wildcard.donor, chroms = chroms),
    output:
        vcf = "{out_dir}/vcf/{donor}-var.vcf.gz"
    shell:
        """
        RAW_VCF={output.vcf}
        RAW_VCF=${{RAW_VCF%%.gz}}

        bcftools concat -a {input.chunk_vcf} > $RAW_VCF
        bgzip -f $RAW_VCF
        tabix -f -p vcf {output.vcf}
        """
