        ### SEMIColon Snakemake
## This Snakemake Pipeline is the workflow for the
## SEMIColon thesis project. The rules run are (# indicates smk rules file):

## [0] merge_fastq: Merge FASTQ files from multiple sequencing runs (where applicable)
## [1] fastp: Preprocess fastq files (quality reports)
## [2] bwa_mem: Align reads to reference
## [2] samblaster: Mark duplicates, option to extract discordant and split reads
## [2] samtools_sort: Sort and convert to bam
## [2] add_rg: Add standard read groups for joint calling
## [2] samtools_index: Index bam files
## [3] samtools_stats: Basic stats on bam files
## [3] mosdepth: Coverage across genome
## [3] plot_mosdepth: Plot mosdepth results NEEDS TO BE CHECKED
## [3] alfred_qc: Bam statistics and plotting
## [4] make_bam_list: Create list of bams for joint variant calling
## [4] generate_regions: Generate regions for parallelized variant calling
## [4] freebayes_variant_calling: Joint variant calling with freebayes
## [4] compress_chunks: Compress vcf chunks
## [4] index_chunks: Index vcf chunks
## [4] concat_vcfs: Concatenate vcf chunks
## [5] bcftools_stats: Basic stats on vcf files

# Laurel Hiatt 09/10/2025

#################
### LIBRARIES ###
#################

import os
import glob
import re

##############
### INPUTS ###
##############
# The input, output, genome fasta, etc are specified in the
# accompanying "CCconfig.yaml".

configfile: '../data/config/spectra_config/spectraconfig.yaml'

# configfile: '../data/config/snakemake_config/CCconfig.yaml'


## directories
top_dir: str = config["top_directory"]
in_dir: str = config["input_directory"]
out_dir: str = config["output_directory"]

# Ensure directories are formatted correctly
top_dir = top_dir.rstrip("/")
in_dir = in_dir.rstrip("/")
out_dir = out_dir.rstrip("/")

# reference data
reference: str = config["reference_genome"]
reference_index: str = config["reference_genome_index"]
chroms = ["chr1","chr2","chr3","chr4","chr6","chr7","chr8","chr9","chr10","chr11","chr12",
    "chr13","chr14","chr15","chr16","chr17", "chr18","chr19","chr20","chr21","chr22","chrX","chrY"]

# study data
samples: list[str] = config["samples"]
donors: list[str] = config["donors"]
matches = config["matches"]

#donors = ["PD34201"] # For testing, only use one donor

######################
### INITIALIZATION ###
######################

# Wildcard constraints; should all be alphanumeric
wildcard_constraints:
    sample = "[A-Za-z0-9_-]+",
    chroms = "[A-Za-z0-9]+",
    i = "[0-9]+",
    out_dir = out_dir,
    donor = "[A-Za-z0-9]+"

# Ensure sample_files is initialized
sample_files = {}

# Create directories.
if not os.path.exists(out_dir):
    os.mkdir(out_dir)

############################
###       PIPELINE       ###
############################

# Define functions for memory during retries.
def mem_xsmall(wildcards, attempt):
    return attempt * 4000

def mem_small(wildcards, attempt):
    return attempt * 8000

def mem_medium(wildcards, attempt):
    return attempt * 16000

def mem_large(wildcards, attempt):
    return attempt * 32000

def mem_xlarge(wildcards, attempt):
    return attempt * 64000

### find all fastq data for samples; useful for top-off sequencing
for sample in samples:
    matching_dirs = glob.glob(f"{top_dir}/**/{sample}", recursive=True)
    # Temporary lists to collect all files for a sample
    temp_r1_files = []
    temp_r2_files = []
    for subdir in matching_dirs:
        subdir_files = glob.glob(f"{subdir}/*.fastq.gz")
        r1_files = [f for f in subdir_files if "_R1" in f]
        r2_files = [f for f in subdir_files if "_R2" in f]

        temp_r1_files.extend(r1_files)
        temp_r2_files.extend(r2_files)
        #print(f"Found {len(r1_files)} R1 and {len(r2_files)} R2 files in {subdir} for sample {sample}")

        if sample not in sample_files:
            sample_files[sample] = {'R1': [], 'R2': []}

        sample_files[sample]['R1'] = list(set(temp_r1_files))
        sample_files[sample]['R2'] = list(set(temp_r2_files))

def get_donor(sample, matches):
    for donor, samples in matches.items():
        if sample in samples['crypt_samples']:
            return donor
    raise KeyError(f"Sample {sample} not found in matches dictionary")

def get_samples_for_donor(donor, matches):
    return [sample for sample, d in matches.items() if d == donor]

#############
### RULES ###
#############

include: "rules/0_merge_fastq.smk"
include: "rules/1_fastp.smk"
include: "rules/2_make_bams.smk"
include: "rules/3_check_bams.smk"
include: "rules/4_make_vcfs.smk"
include: "rules/5_check_vcfs.smk"
include: "rules/6_filter_vcfs.smk"

rule all:
    # final output
    input:
        expand(
            out_dir + "/reports/{sample}-fastp-report.json",
            sample=samples,
        ),
        expand(
            out_dir + "/bam/{sample}-sorted.bam.bai",
            sample = samples,
        ),
        expand(
            out_dir + "/bam/{sample}-sorted.stats",
            sample = samples
        ),
        expand(
            out_dir + "/mosdepth/{donor}_mosdepth_coverage.html",
            donor = donors
        ),
        expand(
            out_dir + "/alfred/{sample}.pdf",
            sample = samples
        ),
        expand(
            out_dir + "/somalier/{donor}/relate.samples.tsv",
            donor = donors
        ),
        expand(
            out_dir + "/vcf/{donor}/summary.pdf",
            donor = donors
        ),
        expand(
            out_dir + "/vcf/{donor}-annotated-var-noLCR.vcf.gz",
            donor = donors
        ),
        expand(
            out_dir + "/mosdepth/{sample}.mosdepth.global.dist.txt",
            sample = samples
        ),
        [
            f"{out_dir}/results/{donor}/{sample}_snv_count.txt"
            for donor, sample in zip(donors, filtered_samples)
        ]