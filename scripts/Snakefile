# /scratch/ucgd/lustre-work/quinlan/data-shared/datasets/spermseq/wgs

configfile: '../data/config.yaml'
in_dir: str = config["input_directory"]
out_dir: str = config["output_directory"]
reference: str = config["reference_genome"]
reference_index: str = config["reference_genome_index"]
samples: list[str] = config["samples"]
nchunks = config["nchunks"]
chunks = list(range(1,nchunks+1))
chroms = ["chr1","chr2","chr3","chr4","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17",
"chr18","chr19","chr20","chr21","chr22","chrX","chrY"]

### IMPORTS ###
import os
import re

# Pipeline plans
# - Variant calling (Call mutations)
#     - FreeBayes?
#     - DeepVariant?
#     - Likely SNVs, maybe indels?
# - Pipeline to process called variants/Vcf
#     - PASS variants, filter
# - Mutational signatures
#     - https://github.com/HLee-Six/colon_microbiopsies what Lee-Six did (in R)
# - Mutational spectra
# - Make plots and save to rational places


# Wildcard constraints; should all be alphanumeric
wildcard_constraints:
    sample = "[A-Za-z0-9]+",
    chroms = "[A-Za-z0-9]+",
    i = "[0-9]+",
    out_dir = out_dir

# Rule 'all', defining all requested output.
rule all:
    input:
        expand("{out_dir}/bam/{sample}-sorted.bai", out_dir = out_dir, sample = samples),
        expand("{out_dir}/vcf/{sample}-var.vcf", out_dir = out_dir, sample = samples)

# Rule 'fastp' preprocesses the reads by detecting and removing adapters,
# filtering reads with an average quality less than 20, and producing
# filtered fastq reads with preprocessing reports.
rule fastp:
    input:
        R1 = in_dir + "/{sample}_R1.merged.trimmed.fastq.gz",
        R2 = in_dir + "/{sample}_R2.merged.trimmed.fastq.gz"
    output:
        r1_clean = "{out_dir}/fastq/{sample}_R1.clean.fastq",
        r2_clean = "{out_dir}/fastq/{sample}_R2.clean.fastq",
        html_report = "{out_dir}/reports/{sample}-fastp-report.html",
        json_report = "{out_dir}/reports/{sample}-fastp-report.json"
    shell:
        """
        fastp --in1 {input.R1} --in2 {input.R2} \
        --out1 {output.r1_clean} --out2 {output.r2_clean} \
        --detect_adapter_for_pe \
        --average_qual 20 \
        --thread {threads} \
        --html {output.html_report} \
        --json {output.json_report}
        """

# Aligns cleaned fastq reads to the defined reference genome
# Mark duplicates and extract discordant and split reads from sam files
# Convert to bam (exclude unmapped reads with -F 4)
rule bwa_mem_bam:
    input:
        r1_clean = rules.fastp.output.r1_clean,
        r2_clean = rules.fastp.output.r2_clean,
        ref = reference
    output:
       zip_bam = "{out_dir}/bam/{sample}.bam.gz"
    threads: 8
    shell:
        """
        bwa mem -t {threads} {input.ref} {input.r1_clean} {input.r2_clean} | samblaster | samtools view -b -F 4 > {output.zip_bam}
        """


rule gunzip:
    input:
        zip_bam = rules.bwa_mem_bam.output.zip_bam
    output:
        bam = "{out_dir}/bam/{sample}.bam"
    shell:
        """
        gunzip {input.zip_bam}
        """

rule sort_bam:
    input:
        bam = rules.gunzip.output.bam
    output:
        bam_sort = "{out_dir}/bam/{sample}-sorted.bam"
    shell:
        """
        samtools sort {input.bam} -o {output.bam_sort}
        """

rule index_bam:
    input:
        bam_sort = rules.sort_bam.output.bam_sort
    output:
        bai = "{out_dir}/bam/{sample}-sorted.bai"
    shell:
        """
        samtools index -b {input.bam_sort} -o {output.bai}
        """

rule generateregions:
    input:
        index = reference_index,
    params:
        chunks = chunks
    output:
        regions = expand("{out_dir}/regions/chunk.{chroms}.region.{i}.bed", i = chunks, out_dir = out_dir, chroms = chroms)
    shell:
        # "../scripts/GenerateFreebayesRegions.R" # This is located in the scripts/ directory of freebayes
        "python variant_calling/fasta_generate_regions.py {input.index} --chunks 9 --bed ../data/output/regions/chunk"


# Current filtering:
### min-alternate-count 2
### min-alternate-qsum 40 : NO LONGER

rule freebayes_variant_calling:
    input:
        bam_sort = rules.sort_bam.output.bam_sort,
        bai = rules.index_bam.output.bai,
        ref = reference,
        regions = "../data/output/regions/chunk.{chroms}.region.{i}.bed"
    output:
       full = temp("{out_dir}/vcf/{chroms}/{sample}-variants.{i}.vcf.gz")
    shell:
        """
        RAW_VCF={output.full}
        RAW_VCF=${{RAW_VCF%%.gz}}
        freebayes --min-alternate-count 2 -f {input.ref} -t {input.regions} {input.bam_sort} > $RAW_VCF
        bgzip -f $RAW_VCF
        tabix -f -p vcf {output.full}
        """

rule ConcatVCFs:
    input:
        chunk_vcf = lambda wildcard: expand("{out_dir}/vcf/{chroms}/{sample}-variants.{i}.vcf.gz",
        i = chunks, out_dir = wildcard.out_dir, sample = wildcard.sample, chroms = chroms)
    output:
        vcf = "{out_dir}/vcf/{sample}-var.vcf"
    threads:4
    shell:
        "bcftools concat -a {input.chunk_vcf} > {output.vcf}"