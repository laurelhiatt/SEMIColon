# /scratch/ucgd/lustre-work/quinlan/data-shared/datasets/spermseq/wgs

configfile: '../data/config.yaml'
in_dir: str = config["input_directory"]
out_dir: str = config["output_directory"]
reference: str = config["reference_genome"]
samples: list[str] = config["samples"]



### IMPORTS ###
import snakemake
import os
import re

# Pipeline plans
# - Variant calling (Call mutations)
#     - FreeBayes?
#     - DeepVariant?
#     - Likely SNVs, maybe indels?
# - Pipeline to process called variants/Vcf
#     - PASS variants, filter
# - Mutational signatures
#     - https://github.com/HLee-Six/colon_microbiopsies what Lee-Six did (in R)
# - Mutational spectra
# - Make plots and save to rational places


# Wildcard constraints; should all be alphanumeric
wildcard_constraints:
    sample = "[A-Za-z0-9]+"

# Rule 'all', defining all requested output.
rule all:
    input:
        expand("{out_dir}/bam/{sample}-sorted.bai", out_dir = out_dir, sample = samples),
        expand("{out_dir}/vcf/{sample}-var.vcf", out_dir = out_dir, sample = samples)


# Rule 'fastp' preprocesses the reads by detecting and removing adapters,
# filtering reads with an average quality less than 20, and producing
# filtered fastq reads with preprocessing reports.
rule fastp:
    input:
        R1 = in_dir + "/{sample}_R1.merged.trimmed.fastq.gz",
        R2 = in_dir + "/{sample}_R2.merged.trimmed.fastq.gz"
    output:
        r1_clean = "{out_dir}/fastq/{sample}_R1.clean.fastq",
        r2_clean = "{out_dir}/fastq/{sample}_R2.clean.fastq",
        html_report = "{out_dir}/reports/{sample}-fastp-report.html",
        json_report = "{out_dir}/reports/{sample}-fastp-report.json"
    conda: "../data/semicolonsmk.yaml"
    shell:
        """
        fastp --in1 {input.R1} --in2 {input.R2} \
        --out1 {output.r1_clean} --out2 {output.r2_clean} \
        --detect_adapter_for_pe \
        --average_qual 20 \
        --thread {threads} \
        --html {output.html_report} \
        --json {output.json_report}
        """

# Aligns cleaned fastq reads to the defined reference genome
# Mark duplicates and extract discordant and split reads from sam files
# Convert to bam (exclude unmapped reads with -F 4)
rule bwa_mem_bam:
    input:
        r1_clean = rules.fastp.output.r1_clean,
        r2_clean = rules.fastp.output.r2_clean,
        ref = reference
    output:
       zip_bam = "{out_dir}/bam/{sample}.bam.gz"
    threads: 8
    conda: "../data/semicolonsmk.yaml"
    shell:
        """
        bwa mem -t {threads} {input.ref} {input.r1_clean} {input.r2_clean} | samblaster | samtools view -b -F 4 > {output.zip_bam}
        """


rule gunzip:
    input:
        zip_bam = rules.bwa_mem_bam.output.zip_bam
    output:
        bam = "{out_dir}/bam/{sample}.bam"
    conda: "../data/semicolonsmk.yaml"
    shell:
        """
        gunzip {input.zip_bam}
        """

rule sort_bam:
    input:
        bam = rules.gunzip.output.bam
    output:
        bam_sort = "{out_dir}/bam/{sample}-sorted.bam"
    conda: "../data/semicolonsmk.yaml"
    shell:
        """
        samtools sort {input.bam} -o {output.bam_sort}
        """

rule index_bam:
    input:
        bam_sort = rules.sort_bam.output.bam_sort
    output:
        bai = "{out_dir}/bam/{sample}-sorted.bai"
    conda: "../data/semicolonsmk.yaml"
    shell:
        """
        samtools index -b {input.bam_sort} -o {output.bai}
        """

rule freebayes:
    input:
        bam_sort = rules.sort_bam.output.bam_sort,
        ref = reference

    output:
        vcf = "{out_dir}/vcf/{sample}-var.vcf"
    shell:
        """
        freebayes -f {input.ref} {input.bam_sort} > {output.vcf}
        """