{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf4dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8a90b",
   "metadata": {},
   "source": [
    "## First, we deal with our actual dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a691a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/config/snakemake_config/CCconfig.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract\n",
    "samples: list[str] = config[\"samples\"]\n",
    "donors: list[str] = config[\"donors\"]\n",
    "matches = config[\"matches\"]\n",
    "regions = config[\"regions\"]\n",
    "cohorts = config[\"cohorts\"]\n",
    "\n",
    "with open(\"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/cohort.txt\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "ages: list[str] = config[\"ages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d5342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for donor, info in matches.items():\n",
    "    crypt_samples = info.get(\"crypt_samples\", [])\n",
    "    for sample in crypt_samples:\n",
    "        rows.append((donor, sample))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"donor\", \"crypt_sample\"])\n",
    "\n",
    "# Add age directly from dict\n",
    "df[\"age\"] = df[\"donor\"].map(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b144a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Regions → donor/crypt_sample/region ---\n",
    "rows = []\n",
    "for donor, region_dict in regions.items():\n",
    "    # print(donor, region_dict)\n",
    "    for region, samples in region_dict.items():\n",
    "        for sample in samples:\n",
    "            rows.append((donor, sample, region))\n",
    "\n",
    "df_regions = pd.DataFrame(rows, columns=[\"donor\", \"crypt_sample\", \"region\"])\n",
    "\n",
    "# Merge regions\n",
    "df = df.merge(df_regions, on=[\"donor\", \"crypt_sample\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ee5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cohorts → donor/cohort ---\n",
    "rows = []\n",
    "for cohort, donors in cohorts.items():\n",
    "    for donor in donors:\n",
    "        rows.append((donor, cohort))\n",
    "\n",
    "df_cohorts = pd.DataFrame(rows, columns=[\"donor\", \"cohort\"])\n",
    "\n",
    "# Merge cohorts\n",
    "df = df.merge(df_cohorts, on=\"donor\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c40371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosdepth_dir = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/mosdepth\"  # top-level directory\n",
    "\n",
    "coverage_rows = []\n",
    "\n",
    "# Iterate over donor subdirectories\n",
    "for donor in os.listdir(mosdepth_dir):\n",
    "    donor_path = os.path.join(mosdepth_dir, donor)\n",
    "    if not os.path.isdir(donor_path):\n",
    "        continue\n",
    "    # Look for HTML files\n",
    "    for file_name in os.listdir(donor_path):\n",
    "        if file_name.endswith(\"_mosdepth_coverage.html\"):\n",
    "            file_path = os.path.join(donor_path, file_name)\n",
    "            with open(file_path) as f:\n",
    "                for line in f:\n",
    "                    if line.strip().startswith(\"Plotly.newPlot('plot-div-total'\"):\n",
    "                        # Extract sample and coverage\n",
    "                        match = re.search(r'\"name\":\\s*\"(.+?)\\s+\\(([\\d\\.]+)\\)\"', line)\n",
    "                        if match:\n",
    "                            sample_name = match.group(1)\n",
    "                            coverage = float(match.group(2))\n",
    "                            coverage_rows.append((donor, sample_name, coverage))\n",
    "                        break  # only first matching line\n",
    "\n",
    "# Create DataFrame\n",
    "df_coverage = pd.DataFrame(coverage_rows, columns=[\"donor\", \"crypt_sample\", \"coverage\"])\n",
    "\n",
    "df = df.merge(df_coverage, on=[\"donor\", \"crypt_sample\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d7a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results\"\n",
    "\n",
    "snv_rows = []\n",
    "\n",
    "# Iterate over donor subdirectories\n",
    "for donor in os.listdir(results_dir):\n",
    "    donor_path = os.path.join(results_dir, donor)\n",
    "    if not os.path.isdir(donor_path):\n",
    "        continue\n",
    "    # Look for *_snv_count.txt files\n",
    "    for file_name in os.listdir(donor_path):\n",
    "        if file_name.endswith(\"_snv_count.txt\"):\n",
    "            sample_name = file_name.replace(\"_snv_count.txt\", \"\")\n",
    "            file_path = os.path.join(donor_path, file_name)\n",
    "            with open(file_path) as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    last_line = lines[-1].strip()\n",
    "                    # Expecting: \"# Total: ##### unique SNVs\"\n",
    "                    match = re.search(r\"# Total:\\s+(\\d+)\\s+unique SNVs\", last_line)\n",
    "                    if match:\n",
    "                        total_snvs = int(match.group(1))\n",
    "                        snv_rows.append((donor, sample_name, total_snvs))\n",
    "\n",
    "# Create DataFrame\n",
    "df_snv = pd.DataFrame(snv_rows, columns=[\"donor\", \"crypt_sample\", \"unique_SNVs\"])\n",
    "\n",
    "# Merge with main df\n",
    "df = df.merge(df_snv, on=[\"donor\", \"crypt_sample\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76782ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_to_process = df[\"donor\"].unique()\n",
    "\n",
    "# Canonical mutation map (collapsed)\n",
    "mutation_map = {\n",
    "    \"C>A\": [\"C>A\", \"G>T\"],\n",
    "    \"C>G\": [\"C>G\", \"G>C\"],\n",
    "    \"C>T\": [\"C>T\", \"G>A\"],\n",
    "    \"T>A\": [\"T>A\", \"A>T\"],\n",
    "    \"T>C\": [\"T>C\", \"A>G\"],\n",
    "    \"T>G\": [\"T>G\", \"A>C\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2fc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class_and_cpg(ref, alt):\n",
    "    ref_str = str(ref)  # ensure string\n",
    "    if ref_str.startswith(\"CpG\"):\n",
    "        ref_base = \"C\"\n",
    "        is_cpg = True\n",
    "    elif ref_str.startswith(\"GpC\"):\n",
    "        ref_base = \"G\"\n",
    "        is_cpg = True\n",
    "    else:\n",
    "        ref_base = ref_str\n",
    "        is_cpg = False\n",
    "\n",
    "    mut = f\"{ref_base}>{alt}\"\n",
    "    mut_class = None\n",
    "    for mclass, muts in mutation_map.items():\n",
    "        if mut in muts:\n",
    "            mut_class = mclass\n",
    "            break\n",
    "\n",
    "    return mut_class, is_cpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d253bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_dir = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results\"\n",
    "mutation_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012a784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for donor in donors_to_process:\n",
    "    donor_path = os.path.join(snv_dir, donor)\n",
    "    if not os.path.isdir(donor_path):\n",
    "        continue\n",
    "    for file_name in os.listdir(donor_path):\n",
    "        if file_name.endswith(\"_snv_count.txt\"):\n",
    "            sample_name = file_name.replace(\"_snv_count.txt\", \"\")\n",
    "            file_path = os.path.join(donor_path, file_name)\n",
    "\n",
    "            df_snv = pd.read_csv(\n",
    "                file_path,\n",
    "                sep=\"\\t\",\n",
    "                comment=\"#\",\n",
    "                usecols=[\"REF\", \"ALT\", \"VAF\"]\n",
    "            )\n",
    "\n",
    "            # Assign mutation class and CpG\n",
    "            results = df_snv.apply(lambda x: assign_class_and_cpg(x.REF, x.ALT), axis=1)\n",
    "            df_snv[\"mut_class\"] = results.apply(lambda x: x[0])\n",
    "            df_snv[\"is_CpG\"] = results.apply(lambda x: x[1])\n",
    "\n",
    "            # Count frequencies\n",
    "            counts = df_snv[\"mut_class\"].value_counts().to_dict()\n",
    "            counts[\"CpG\"] = df_snv[\"is_CpG\"].sum()\n",
    "            counts[\"donor\"] = donor\n",
    "            counts[\"crypt_sample\"] = sample_name\n",
    "\n",
    "            mutation_counts.append(counts)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_mutation = pd.DataFrame(mutation_counts).fillna(0)\n",
    "\n",
    "# Merge with your main df\n",
    "df = df.merge(df_mutation, on=[\"donor\", \"crypt_sample\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba123dec",
   "metadata": {},
   "source": [
    "## Next, let's do the Lee-Six data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6933c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leesix = pd.read_csv(\"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/LeeSixcohort.txt\", sep=\"\\t\")\n",
    "leesix_clean = leesix.drop(columns=['sample_title', 'sample_accession_id', 'file_name', 'file_accession_id', 'accession_id'])\n",
    "leesix_clean = leesix_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33212f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/config/test_config/testconfig.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract and subset\n",
    "samples: list[str] = config[\"samples\"]\n",
    "mask_to_keep = leesix_clean['subject_id'].isin(samples)\n",
    "leesix_clean = leesix_clean[mask_to_keep]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c251d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "leesix_clinical = pd.read_csv(\"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/LeeSixclinical.csv\")\n",
    "donors: list[str] = config[\"donors\"]\n",
    "mask_to_keep = leesix_clinical['patient'].isin(donors)\n",
    "leesix_clinical = leesix_clinical[mask_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d70b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "leesix_full = pd.merge(leesix_clean, leesix_clinical, on=['patient', 'sex', 'age'], how= 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b878ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosdepth_dir = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/mosdepth\"  # top-level directory\n",
    "\n",
    "coverage_rows = []\n",
    "\n",
    "# Iterate over donor subdirectories\n",
    "for donor in os.listdir(mosdepth_dir):\n",
    "    donor_path = os.path.join(mosdepth_dir, donor)\n",
    "    if not os.path.isdir(donor_path):\n",
    "        continue\n",
    "    # Look for HTML files\n",
    "    for file_name in os.listdir(donor_path):\n",
    "        if file_name.endswith(\"_mosdepth_coverage.html\"):\n",
    "            file_path = os.path.join(donor_path, file_name)\n",
    "            with open(file_path) as f:\n",
    "                for line in f:\n",
    "                    if line.strip().startswith(\"Plotly.newPlot('plot-div-total'\"):\n",
    "                        # Extract sample and coverage\n",
    "                        match = re.search(r'\"name\":\\s*\"(.+?)\\s+\\(([\\d\\.]+)\\)\"', line)\n",
    "                        if match:\n",
    "                            sample_name = match.group(1)\n",
    "                            coverage = float(match.group(2))\n",
    "                            coverage_rows.append((donor, sample_name, coverage))\n",
    "                        break  # only first matching line\n",
    "\n",
    "# Create DataFrame\n",
    "df_coverage = pd.DataFrame(coverage_rows, columns=[\"patient\", \"subject_id\", \"coverage\"])\n",
    "\n",
    "leesix_full = leesix_full.merge(df_coverage, on=[\"patient\", \"subject_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2da1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results\"\n",
    "\n",
    "snv_rows = []\n",
    "\n",
    "# Iterate over donor subdirectories\n",
    "for donor in donors:\n",
    "    donor_path = os.path.join(results_dir, donor)\n",
    "    if not os.path.isdir(donor_path):\n",
    "        continue\n",
    "    # Look for *_snv_count.txt files\n",
    "    for file_name in os.listdir(donor_path):\n",
    "        if file_name.endswith(\"_snv_count.txt\"):\n",
    "            sample_name = file_name.replace(\"_snv_count.txt\", \"\")\n",
    "            file_path = os.path.join(donor_path, file_name)\n",
    "            with open(file_path) as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    last_line = lines[-1].strip()\n",
    "                    # Expecting: \"# Total: ##### unique SNVs\"\n",
    "                    # will need to change when I update these VAFs, right now I'm running stuff for the unvariant called Lee-Six donors\n",
    "                    match = re.search(r\"Total:\\s+(\\d+)\\s+unique SNVs\", last_line)\n",
    "                    if match:\n",
    "                        total_snvs = int(match.group(1))\n",
    "                        snv_rows.append((donor, sample_name, total_snvs))\n",
    "\n",
    "# Create DataFrame\n",
    "df_snv = pd.DataFrame(snv_rows, columns=[\"patient\", \"subject_id\", \"unique_SNVs\"])\n",
    "\n",
    "# Merge with main df\n",
    "leesix_full = leesix_full.merge(df_snv, on=[\"patient\", \"subject_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b07d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_to_process = leesix_full[\"patient\"].unique()\n",
    "\n",
    "# Canonical mutation map (collapsed)\n",
    "mutation_map = {\n",
    "    \"C>A\": [\"C>A\", \"G>T\"],\n",
    "    \"C>G\": [\"C>G\", \"G>C\"],\n",
    "    \"C>T\": [\"C>T\", \"G>A\"],\n",
    "    \"T>A\": [\"T>A\", \"A>T\"],\n",
    "    \"T>C\": [\"T>C\", \"A>G\"],\n",
    "    \"T>G\": [\"T>G\", \"A>C\"],\n",
    "}\n",
    "\n",
    "def assign_class_and_cpg(ref, alt):\n",
    "    ref_str = str(ref)  # ensure string\n",
    "    if ref_str.startswith(\"CpG\"):\n",
    "        ref_base = \"C\"\n",
    "        is_cpg = True\n",
    "    elif ref_str.startswith(\"GpC\"):\n",
    "        ref_base = \"G\"\n",
    "        is_cpg = True\n",
    "    else:\n",
    "        ref_base = ref_str\n",
    "        is_cpg = False\n",
    "\n",
    "    mut = f\"{ref_base}>{alt}\"\n",
    "    mut_class = None\n",
    "    for mclass, muts in mutation_map.items():\n",
    "        if mut in muts:\n",
    "            mut_class = mclass\n",
    "            break\n",
    "\n",
    "    return mut_class, is_cpg\n",
    "\n",
    "snv_dir = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results\"\n",
    "mutation_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617e97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for donor in donors_to_process:\n",
    "    donor_path = os.path.join(snv_dir, donor)\n",
    "    if not os.path.isdir(donor_path):\n",
    "        continue\n",
    "    for file_name in os.listdir(donor_path):\n",
    "        if file_name.endswith(\"_snv_count.txt\"):\n",
    "            sample_name = file_name.replace(\"_snv_count.txt\", \"\")\n",
    "            file_path = os.path.join(donor_path, file_name)\n",
    "\n",
    "            df_snv = pd.read_csv(\n",
    "                file_path,\n",
    "                sep=\"\\t\",\n",
    "                comment=\"#\",\n",
    "                usecols=[\"REF\", \"ALT\", \"VAF\"]\n",
    "            )\n",
    "\n",
    "            # Assign mutation class and CpG\n",
    "            results = df_snv.apply(lambda x: assign_class_and_cpg(x.REF, x.ALT), axis=1)\n",
    "            df_snv[\"mut_class\"] = results.apply(lambda x: x[0])\n",
    "            df_snv[\"is_CpG\"] = results.apply(lambda x: x[1])\n",
    "\n",
    "            # Count frequencies\n",
    "            counts = df_snv[\"mut_class\"].value_counts().to_dict()\n",
    "            counts[\"CpG\"] = df_snv[\"is_CpG\"].sum()\n",
    "            counts[\"patient\"] = donor\n",
    "            counts[\"subject_id\"] = sample_name\n",
    "\n",
    "            mutation_counts.append(counts)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_mutation = pd.DataFrame(mutation_counts).fillna(0)\n",
    "\n",
    "# Merge with your main df\n",
    "leesix_full = leesix_full.merge(df_mutation, on=[\"patient\", \"subject_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/Hiattdataframe.csv', index=False) # index=False prevents writing the DataFrame index to the CSV\n",
    "\n",
    "leesix_full.to_csv('/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/LeeSixdataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataframe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
