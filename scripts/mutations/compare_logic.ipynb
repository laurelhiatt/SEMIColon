{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168d0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b066beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collapsed canonical mutation map\n",
    "mutation_map = {\n",
    "    \"C>A\": [\"C>A\", \"G>T\"],\n",
    "    \"C>G\": [\"C>G\", \"G>C\"],\n",
    "    \"C>T\": [\"C>T\", \"G>A\"],\n",
    "    \"T>A\": [\"T>A\", \"A>T\"],\n",
    "    \"T>C\": [\"T>C\", \"A>G\"],\n",
    "    \"T>G\": [\"T>G\", \"A>C\"],\n",
    "}\n",
    "# reverse lookup: e.g. \"G>A\" -> \"C>T\"\n",
    "_rev_lookup = {}\n",
    "for k, vals in mutation_map.items():\n",
    "    for v in vals:\n",
    "        _rev_lookup[v.upper()] = k\n",
    "CANONICAL_ORDER = list(mutation_map.keys())\n",
    "\n",
    "_total_re = re.compile(r\"Total\\s*[:]\\s*(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "def assign_class_simple(ref, alt):\n",
    "    \"\"\"\n",
    "    Very simple mapping:\n",
    "      - If ref starts with 'CpG' -> treat ref_base = 'C' (is_cpg True)\n",
    "      - If ref starts with 'GpC' -> treat ref_base = 'G' (is_cpg True)\n",
    "      - Else, if ref is a single base or contains a single base, use that base.\n",
    "    Returns (mut_class_or_None, is_cpg_bool)\n",
    "    \"\"\"\n",
    "    if ref is None or alt is None:\n",
    "        return None, False\n",
    "    ref_s = str(ref).strip()\n",
    "    alt_s = str(alt).strip().upper()\n",
    "\n",
    "    if ref_s == \"\" or alt_s == \"\":\n",
    "        return None, False\n",
    "\n",
    "    ref_up = ref_s.upper()\n",
    "    is_cpg = False\n",
    "\n",
    "    if ref_up.startswith(\"CPG\"):\n",
    "        ref_base = \"C\"\n",
    "        is_cpg = True\n",
    "    elif ref_up.startswith(\"GPC\"):\n",
    "        ref_base = \"G\"\n",
    "        is_cpg = True\n",
    "    else:\n",
    "        # simple fallback: look for first A/C/G/T in the token\n",
    "        m = re.search(r\"[ACGTacgt]\", ref_s)\n",
    "        ref_base = m.group(0).upper() if m else None\n",
    "\n",
    "    if ref_base is None or ref_base not in {\"A\",\"C\",\"G\",\"T\"}:\n",
    "        return None, is_cpg\n",
    "    if len(alt_s) != 1 or alt_s not in {\"A\",\"C\",\"G\",\"T\"}:\n",
    "        return None, is_cpg\n",
    "\n",
    "    change = f\"{ref_base}>{alt_s}\".upper()\n",
    "    mut_class = _rev_lookup.get(change)  # collapse complements\n",
    "    return mut_class, is_cpg\n",
    "\n",
    "def parse_file(path):\n",
    "    \"\"\"\n",
    "    Parse a single .snv_count.txt file.\n",
    "    Returns (total_if_found_or_None, list_of_mut_classes)\n",
    "    where list_of_mut_classes contains tuples (mut_class_or_None, is_cpg)\n",
    "    \"\"\"\n",
    "    total = None\n",
    "    muts = []\n",
    "    with open(path) as fh:\n",
    "        for line in fh:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\"#\"):\n",
    "                m = _total_re.search(line)\n",
    "                if m and total is None:\n",
    "                    try:\n",
    "                        total = int(m.group(1))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                continue\n",
    "            parts = re.split(r\"\\s+\", line)\n",
    "            # try to detect REF and ALT: default CHROM POS REF ALT VAF -> REF at idx 2, ALT at idx 3\n",
    "            ref = alt = None\n",
    "            if len(parts) >= 4:\n",
    "                ref_candidate, alt_candidate = parts[2], parts[3]\n",
    "                # accept alt if single base\n",
    "                if re.fullmatch(r\"[ACGTacgt]\", alt_candidate):\n",
    "                    ref = ref_candidate\n",
    "                    alt = alt_candidate\n",
    "            # fallback: search for single-letter tokens among first 6 fields\n",
    "            if ref is None or alt is None:\n",
    "                ref = alt = None\n",
    "                for p in parts[:6]:\n",
    "                    if ref is None and re.fullmatch(r\"[ACGTacgt]|[ACGTacgt]{3}|CpG|GpC\", p):\n",
    "                        ref = p\n",
    "                        continue\n",
    "                    if ref is not None and re.fullmatch(r\"[ACGTacgt]\", p):\n",
    "                        alt = p\n",
    "                        break\n",
    "            if ref is None or alt is None:\n",
    "                continue\n",
    "            mut_class, is_cpg = assign_class_simple(ref, alt)\n",
    "            muts.append((mut_class, is_cpg))\n",
    "    return total, muts\n",
    "\n",
    "def collect_files(dirpath):\n",
    "    files = glob.glob(os.path.join(dirpath, \"*.snv_count.txt\"))\n",
    "    mapping = {}\n",
    "    for f in files:\n",
    "        base = os.path.basename(f)\n",
    "        sample = base[:-len(\".snv_count.txt\")] if base.endswith(\".snv_count.txt\") else os.path.splitext(base)[0]\n",
    "        mapping[sample] = f\n",
    "    return mapping\n",
    "\n",
    "def main(dir1, dir2, outdir):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    per_sample = os.path.join(outdir, \"per_sample\")\n",
    "    os.makedirs(per_sample, exist_ok=True)\n",
    "\n",
    "    files1 = collect_files(dir1)\n",
    "    files2 = collect_files(dir2)\n",
    "\n",
    "    # treat as separate samples\n",
    "    sample_paths = {}\n",
    "    cohort = {}\n",
    "    for s, p in files1.items():\n",
    "        name = f\"{s}_dir1\"\n",
    "        sample_paths[name] = p\n",
    "        cohort[name] = \"dir1\"\n",
    "    for s, p in files2.items():\n",
    "        name = f\"{s}_dir2\"\n",
    "        sample_paths[name] = p\n",
    "        cohort[name] = \"dir2\"\n",
    "    samples = sorted(sample_paths.keys())\n",
    "\n",
    "    # build counts matrix\n",
    "    counts_df = pd.DataFrame(0, index=CANONICAL_ORDER, columns=samples, dtype=int)\n",
    "    totals_by_sample = {}\n",
    "\n",
    "    # also aggregated totals per directory (from # Total lines if present, else from counted variants)\n",
    "    agg_total_dir1 = 0\n",
    "    agg_total_dir2 = 0\n",
    "\n",
    "    for s in samples:\n",
    "        path = sample_paths[s]\n",
    "        total_line_val, muts = parse_file(path)\n",
    "        # if the file had an explicit total, use it; else compute from parsed muts\n",
    "        if total_line_val is not None:\n",
    "            totals_by_sample[s] = total_line_val\n",
    "        else:\n",
    "            totals_by_sample[s] = len(muts)\n",
    "        # count per class\n",
    "        counter = Counter()\n",
    "        for mut_class, is_cpg in muts:\n",
    "            if mut_class:\n",
    "                # ensure CpG/GpC prefixed refs were converted to base before mapping, so they count\n",
    "                counter[mut_class] += 1\n",
    "        for k in CANONICAL_ORDER:\n",
    "            counts_df.at[k, s] = counter.get(k, 0)\n",
    "        # update aggregated totals per directory\n",
    "        if cohort[s] == \"dir1\":\n",
    "            agg_total_dir1 += totals_by_sample[s]\n",
    "        else:\n",
    "            agg_total_dir2 += totals_by_sample[s]\n",
    "        # write per-sample raw counts (optional)\n",
    "        outps = os.path.join(per_sample, f\"{s}_spectra.tsv\")\n",
    "        with open(outps, \"w\", newline=\"\") as fh:\n",
    "            w = csv.writer(fh, delimiter=\"\\t\")\n",
    "            w.writerow([\"canonical_mutation\", \"count\"])\n",
    "            for k in CANONICAL_ORDER:\n",
    "                w.writerow([k, counts_df.at[k, s]])\n",
    "\n",
    "    # compute proportions per sample (columns sum to 1)\n",
    "    prop = counts_df.astype(float).copy()\n",
    "    for col in prop.columns:\n",
    "        ssum = prop[col].sum()\n",
    "        if ssum == 0:\n",
    "            prop[col] = 0.0\n",
    "        else:\n",
    "            prop[col] = prop[col] / ssum\n",
    "\n",
    "    # save matrices\n",
    "    prop.index.name = \"MutationType\"\n",
    "    prop.to_csv(os.path.join(outdir, \"proportions_matrix.tsv\"), sep=\"\\t\", float_format=\"%.6f\")\n",
    "    prop.reset_index().melt(id_vars=\"MutationType\", var_name=\"Sample\", value_name=\"Proportion\") \\\n",
    "        .assign(Cohort=lambda df: df[\"Sample\"].map(cohort)) \\\n",
    "        .to_csv(os.path.join(outdir, \"proportions_long.tsv\"), sep=\"\\t\", index=False, float_format=\"%.6f\")\n",
    "\n",
    "    # produce cohort boxplot (two boxes per mutation type)\n",
    "    df_long = prop.reset_index().melt(id_vars=\"MutationType\", var_name=\"Sample\", value_name=\"Proportion\")\n",
    "    df_long[\"Cohort\"] = df_long[\"Sample\"].map(cohort)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax = sns.boxplot(data=df_long, x=\"MutationType\", y=\"Proportion\", hue=\"Cohort\",\n",
    "                     order=CANONICAL_ORDER, showfliers=False)\n",
    "    sns.stripplot(data=df_long, x=\"MutationType\", y=\"Proportion\", hue=\"Cohort\",\n",
    "                  dodge=True, order=CANONICAL_ORDER, jitter=True, size=3, alpha=0.6)\n",
    "    # tidy legend (remove duplicate legend entries)\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.legend_.remove()\n",
    "        ax.legend(title=\"Cohort\", loc=\"upper right\")\n",
    "    ax.set_title(\"Per-sample mutation-type proportions (dir1 vs dir2)\")\n",
    "    ax.set_ylabel(\"Proportion\")\n",
    "    ax.set_xlabel(\"Mutation Type\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, \"spectra_proportions_boxplot_by_cohort.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # one-line totals summary between directories\n",
    "    diff = agg_total_dir2 - agg_total_dir1\n",
    "    summary_line = f\"Total unique SNVs: dir1={agg_total_dir1}  dir2={agg_total_dir2}  difference(dir2-dir1)={diff}\"\n",
    "    print(summary_line)\n",
    "    with open(os.path.join(outdir, \"totals_summary.txt\"), \"w\") as fh:\n",
    "        fh.write(summary_line + \"\\n\")\n",
    "\n",
    "    # also write totals per sample\n",
    "    with open(os.path.join(outdir, \"totals_comparison.tsv\"), \"w\", newline=\"\") as fh:\n",
    "        w = csv.writer(fh, delimiter=\"\\t\")\n",
    "        w.writerow([\"sample_with_cohort\", \"cohort\", \"total_unique_snvs\"])\n",
    "        for s in samples:\n",
    "            w.writerow([s, cohort[s], totals_by_sample[s]])\n",
    "\n",
    "    print(\"Wrote outputs to:\", outdir)\n",
    "    print(\" - proportions_matrix.tsv, proportions_long.tsv\")\n",
    "    print(\" - spectra_proportions_boxplot_by_cohort.png\")\n",
    "    print(\" - totals_summary.txt and totals_comparison.tsv\")\n",
    "    print(\" - per-sample TSVs in\", per_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9596ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique SNVs: dir1=247888  dir2=246911  difference(dir2-dir1)=-977\n",
      "Wrote outputs to: /uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/continueornot/\n",
      " - proportions_matrix.tsv, proportions_long.tsv\n",
      " - spectra_proportions_boxplot_by_cohort.png\n",
      " - totals_summary.txt and totals_comparison.tsv\n",
      " - per-sample TSVs in /uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/continueornot/per_sample\n"
     ]
    }
   ],
   "source": [
    "#in1 = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/Hiatt_continue2Dec22025/txtfiles/\"\n",
    "#in2 = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/Hiatt_okay2Dec82025/txtfiles/\"\n",
    "\n",
    "in1 = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/Hiatt_okay2Dec82025/txtfiles/\"\n",
    "in2 = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/Hiatt_continueif2unknownDec82025/txtfiles\"\n",
    "\n",
    "out = \"/uufs/chpc.utah.edu/common/HIPAA/u1264408/u1264408/Git/SEMIColon/data/output/CellCut/results/continueornot/\"\n",
    "main(in1, in2, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743583e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proportion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
